
Spark

A C A D G I L D 

1. What is RDD?
RDD stands for Resilient Distributed DataSet.RDDis a fundamental data structure of Spark. It is an immutable distributed collection of objects. Each dataset in RDD is divided into logical partitions, which may be computed on different nodes of the cluster. RDDs can contain any type of Python, Java, or Scala objects, including user-defined classes.

2. Define Partitions.
RDD (Resilient Distributed Dataset) is main logical data unit in Spark. An RDD is distributed collection of objects. Distributed means, each RDD is divided into multiple partitions. Each of these partitions are logical entities, that can reside in memory or stored on disk of different machines in a cluster. RDDs are immutable (Read Only) data structure. You can’t change original RDD, but you can always transform it into different RDD with all changes you want.

3. What operations does RDD support?
Spark provides a rich set of operators to manipulate RDDs. RDD performs 2 operations mainly, transformations and actions

4. What do you understand by Transformations in Spark?
Transformations create new RDD from existing RDD like map, reduceByKey and filter. Transformations are executed on demand. That means they are computed lazily.

5. Define Actions.
Actions return final results of RDD computations. Actions triggers execution using lineage graph to load the data into original RDD, carry out all intermediate transformations and return final results to Driver program or write it out to file system.